<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="application/xhtml+xml;charset=utf-8" />
  <title>Used Capacity of the English Language - Jorge Rodr&iacute;guez's Blog</title>

  <link href='https://fonts.googleapis.com/css?family=Martel:300,800' rel='stylesheet' type='text/css'>
  <link href='https://fonts.googleapis.com/css?family=Source Code Pro:300' rel='stylesheet' type='text/css'>

  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      extensions: ["tex2jax.js"],
      jax: ["input/TeX", "output/HTML-CSS"],
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true
      },
      "HTML-CSS": { availableFonts: ["TeX"] }
    });
  </script>
  <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/2.6-latest/MathJax.js">
  </script>

  <link href="style.css" rel="stylesheet" type="text/css" />

</head>
<body>
  <div id="everything">

  <div id='nav'>
    <em>Think Small - Jorge Rodr&iacute;guez's Blog</em> |
    <a href="index.htm">Archives</a> |
    <a href="/">Home</a> |
    <a href="http://twitter.com/VinoBS">Twitter</a> |
    <a href="rss.xml">RSS</a>
  </div>

  <h1>Used Capacity of the English Language</h1>

<p>A thought experiment.</p>
<p>Out of all possible grammatically correct and sensible sentences in the English language, how many of them have been used by humans at some point? Is it $10\%$? $0.1\%$? $0.000001\%$? $10^{-100}\%$?</p>
<p>It's not unreasonable to believe that the vast majority of possible English sentences are untapped. But what's the order of magnitude? How much of the boundary of our own language is unexplored? I could easily write a sentence that nobody else in the history of mankind is likely to ever have said, for example the one you are currently reading, but how many such sentences exist? The difference between $0.1\%$ of sentences used and $0.000001\%$ and $10^{-100}\%$ is vast and I think knowing the order of magnitude could be informative.</p>
<p>How would one go about estimating this? Perhaps if you took a large repository of text such as the Cambridge library or Google Scholar and counted every unique sentence  (hell, the majority of them will be unique anyway so just count them up) you could get an idea of how many unique sentences have ever been used. How many of those could there be? Say each book has about 100,000 sentences (a quick Google search tells me that's the number of sentences in a Harry Potter novel) and there have been 130 million unique books printed according to Google Books. Most of those have probably been in non-English languages but to compensate for Internet content and unpublished content and to be optimistic I'll use the figure of 130 million. That comes out to 13 trillion sentences. Then you only need to compare it to every possible sensible English sentence.</p>
<p>How would one go about estimating that? I'm not a linguist, but I would start by taking every basic grammar structure in the English language and iterating. For example, start with "[noun] [verb]." There are maybe 80,000 nouns and 2,500 verbs, but not all of them are sensible combinations. For example "The dog runs" makes sense and maybe even "the dog talks" could make sense in some contexts (e.g. fiction) but there are probably no contexts for which "the dog billows" makes sense. Having no idea as to the number of noun/verb pairings that are sensible I'm going to guess that we can get about 40,000 of our nouns paired with maybe 1,000 verbs this way, so we already have 40,000,000 sentences right there.</p>
<p>Now let's add possible adjectives. There are maybe 40,000 of those, of which perhaps 20,000 can be paired with a noun sensibly. That makes 800 billion sentences so far. There aren't that many adverbs so I'll ignore them. We've only covered a single sentence structure though, the simplest possible sentence. We've not done any compound sentences or sentences with dependent clauses and so on, so 800 billion stands as a lower bound for the number of sensible permutations of a sentence. For a sentence with any complex sort of structure I imagine it would be exponentially greater. We could very easily pass our 13 trillion used sentences, but I'm going to stop estimating because it will get out of hand so quickly and my skills with combinatorics are beginning to fail me.</p>
<p>In any case, once all possible combinations of all possible sentence structures are summed, you have the total possible number of sentences in the modern English language. Everything ever written is in there somewhere, every line of Shakespeare, every blog post, even this sentence. How much of that have we managed to find? If we treat the boundaries of the English language as the boundaries of society's capacity to learn and grow, then knowing how much more there is gives us an indication of how much potential we have as the human species.</p><br clear="both" />
<div id="date"><a href="/">Jorge Rodriguez</a>, <a href="1.htm">May 3, 2014</a></div>

<div id="similar"><h2>Similar:</h2><ul><li><a href='5.htm'>Whacking at Screws with Hammers</a></li><li><a href='4.htm'>Designing by Sense of Feel</a></li><li><a href='10.htm'>Numerical Methods for Physics Integration in Video Games</a></li></ul></div>
</div>


<div id="footer">
</div>

</body>
<!-- 03 February 2017 at 02:28:31 GMT -->
</html>